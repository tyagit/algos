{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitanaconda3condaa138145ab3414143ab813b98cd37c17c",
   "display_name": "Python 3.6.5 64-bit ('Anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow-datasets\n",
    "#github repo: https://github.com/tensorflow/datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "\tnetwork.append(hidden_layer)\n",
    "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code will create a network with 2 input neurons, 1 hidden neuron and 2 output neurons.\n",
    "\n",
    "- weights for hidden neuron will be coming from 2 input neurons + 1 bias\n",
    "- weights for output neuron will be coming from 1 hidden neuron + 1 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'weights': [0.6394267984578837, 0.025010755222666936, 0.27502931836911926]}]\n[{'weights': [0.22321073814882275, 0.7364712141640124]}, {'weights': [0.6766994874229113, 0.8921795677048454]}]\n"
    }
   ],
   "source": [
    "seed(42)\n",
    "network = initialize_network(2, 1, 2)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagate:\n",
    "- Neuron Activation\n",
    "- Neuron Transfer\n",
    "- Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuron activation function\n",
    "#activation = sum(weight_i * input_i) + bias\n",
    "\n",
    "def activate_neuron(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights) - 1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuron transfer activation\n",
    "#using sigmoid function\n",
    "\n",
    "from math import exp\n",
    "\n",
    "def transfer(activation):\n",
    "    return 1.0/(1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward propagate\n",
    "#This will return the outputs from the last layer\n",
    "\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate_neuron(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.710090547112879, 0.7982323416770263]\n"
    }
   ],
   "source": [
    "#Test forward propagation\n",
    "\n",
    "row = [1, 0]\n",
    "output = forward_propagate(network, row)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagate error\n",
    "- Transfer Derivative\n",
    "- Error Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer derivative - slope of the output value of a neuron\n",
    "#for sigmoid transfer function - derivative = output * (1.0 - output)\n",
    "\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error backpropagation\n",
    "#error for output layers = (expected - output) * transfer_derivative(output) \n",
    "#error for hidden layers = (weight_k * error_j) * transfer_derivative(output)\n",
    "#error_j is the error signal from the jth neuron in the output layer, \n",
    "#weight_k is the weight that connects the kth neuron to the current neuron and \n",
    "#output is the output for the current neuron.\n",
    "\n",
    "def backpropagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'weights': [0.6394267984578837, 0.025010755222666936, 0.27502931836911926], 'output': 0.7139111559058509, 'delta': -0.002172917106539774}]\n[{'weights': [0.22321073814882275, 0.7364712141640124], 'output': 0.710090547112879, 'delta': -0.14618063323611788}, {'weights': [0.6766994874229113, 0.8921795677048454], 'output': 0.7982323416770263, 'delta': 0.032496188653557974}]\n"
    }
   ],
   "source": [
    "#test backpropagation\n",
    "\n",
    "expected = [0, 1]\n",
    "backpropagate_error(network, expected)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network\n",
    "- Update weights\n",
    "- Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update weights\n",
    "#weight = weight + learning_rate*input*error\n",
    "\n",
    "def update_weights(network, row, learning_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i!=0:\n",
    "            inputs = [neuron['output'] for neuron in network[i-1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += learning_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += learning_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[-1]] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackpropagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">epoch=0, lrate=0.500, error=6.350\n>epoch=1, lrate=0.500, error=5.531\n>epoch=2, lrate=0.500, error=5.221\n>epoch=3, lrate=0.500, error=4.951\n>epoch=4, lrate=0.500, error=4.519\n>epoch=5, lrate=0.500, error=4.173\n>epoch=6, lrate=0.500, error=3.835\n>epoch=7, lrate=0.500, error=3.506\n>epoch=8, lrate=0.500, error=3.192\n>epoch=9, lrate=0.500, error=2.898\n>epoch=10, lrate=0.500, error=2.626\n>epoch=11, lrate=0.500, error=2.377\n>epoch=12, lrate=0.500, error=2.153\n>epoch=13, lrate=0.500, error=1.953\n>epoch=14, lrate=0.500, error=1.774\n>epoch=15, lrate=0.500, error=1.614\n>epoch=16, lrate=0.500, error=1.472\n>epoch=17, lrate=0.500, error=1.346\n>epoch=18, lrate=0.500, error=1.233\n>epoch=19, lrate=0.500, error=1.132\n[{'weights': [-1.4688375095432327, 1.850887325439514, 1.0858178629550297], 'output': 0.029980305604426185, 'delta': -0.0059546604162323625}, {'weights': [0.37711098142462157, -0.0625909894552989, 0.2765123702642716], 'output': 0.9456229000211323, 'delta': 0.0026279652850863837}]\n[{'weights': [2.515394649397849, -0.3391927502445985, -0.9671565426390275], 'output': 0.23648794202357587, 'delta': -0.04270059278364587}, {'weights': [-2.5584149848484263, 1.0036422106209202, 0.42383086467582715], 'output': 0.7790535202438367, 'delta': 0.03803132596437354}]\n"
    }
   ],
   "source": [
    "# Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\n"
    }
   ],
   "source": [
    "for row in dataset:\n",
    "\tprediction = predict(network, row)\n",
    "\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}